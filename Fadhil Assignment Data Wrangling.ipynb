{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e6118e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Data:\n",
      "   customer_id customer_name    age         country  purchase_amount  \\\n",
      "0            1         Alice   25.0             USA            100.5   \n",
      "1            2           Bob    NaN   United States              NaN   \n",
      "2            3       Charlie   35.0              UK            200.0   \n",
      "3            4         David   45.0  United Kingdom            150.0   \n",
      "4            5           Eve  120.0             USA           5000.0   \n",
      "5            6         Frank   29.0              UK            120.0   \n",
      "6            7         Grace    NaN             NaN              NaN   \n",
      "7            8        Hannah   33.0             USA            180.0   \n",
      "8            8        hannah   33.0             usa            180.0   \n",
      "\n",
      "   purchase_frequency             date  \n",
      "0                10.0       2025-03-01  \n",
      "1                 NaN       2025/03/02  \n",
      "2                20.0             None  \n",
      "3                15.0  March 3rd, 2025  \n",
      "4                 NaN             None  \n",
      "5                12.0       03-04-2025  \n",
      "6                 NaN             None  \n",
      "7                18.0             None  \n",
      "8                18.0             None  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = {\n",
    "    'customer_id': [1, 2, 3, 4, 5, 6, 7, 8, 8],  # Duplicate customer_id (row 8)\n",
    "    'customer_name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve', 'Frank', 'Grace', 'Hannah', 'hannah'],  # Inconsistent text case\n",
    "    'age': [25, np.nan, 35, 45, 120, 29, np.nan, 33, 33],  # Missing values and outlier (age=120)\n",
    "    'country': ['USA', 'United States', 'UK', 'United Kingdom', 'USA', 'UK', np.nan, 'USA', 'usa'],  # Inconsistent naming conventions\n",
    "    'purchase_amount': [100.5, np.nan, 200.0, 150.0, 5000.0, 120.0, np.nan, 180.0, 180.0],  # Missing values and outlier (purchase_amount=5000)\n",
    "    'purchase_frequency': [10, np.nan, 20, 15, np.nan, 12, np.nan, 18, 18],  # Missing values\n",
    "    'date': ['2025-03-01', '2025/03/02', None, 'March 3rd, 2025', None, '03-04-2025', None, None, None]  # Inconsistent date formats and missing values\n",
    "}\n",
    "\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "print(\"Sample Data:\")\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22378a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Phase 1: Data Loading and Initial Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13819fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initial Data:\n",
      "   customer_id customer_name    age         country  purchase_amount  \\\n",
      "0            1         Alice   25.0             USA            100.5   \n",
      "1            2           Bob    NaN   United States              NaN   \n",
      "2            3       Charlie   35.0              UK            200.0   \n",
      "3            4         David   45.0  United Kingdom            150.0   \n",
      "4            5           Eve  120.0             USA           5000.0   \n",
      "\n",
      "   purchase_frequency             date  \n",
      "0                10.0       2025-03-01  \n",
      "1                 NaN       2025/03/02  \n",
      "2                20.0             None  \n",
      "3                15.0  March 3rd, 2025  \n",
      "4                 NaN             None  \n",
      "\n",
      "Data Types:\n",
      "customer_id             int64\n",
      "customer_name          object\n",
      "age                   float64\n",
      "country                object\n",
      "purchase_amount       float64\n",
      "purchase_frequency    float64\n",
      "date                   object\n",
      "dtype: object\n",
      "\n",
      "Shape of Dataset:\n",
      "Rows: 9, Columns: 7\n",
      "\n",
      "Missing Values:\n",
      "customer_id           0\n",
      "customer_name         0\n",
      "age                   2\n",
      "country               1\n",
      "purchase_amount       2\n",
      "purchase_frequency    3\n",
      "date                  5\n",
      "dtype: int64\n",
      "\n",
      "Descriptive Statistics:\n",
      "       customer_id         age  purchase_amount  purchase_frequency\n",
      "count     9.000000    7.000000         7.000000            6.000000\n",
      "mean      4.888889   45.714286       847.214286           15.500000\n",
      "std       2.571208   33.330238      1831.547430            3.885872\n",
      "min       1.000000   25.000000       100.500000           10.000000\n",
      "25%       3.000000   31.000000       135.000000           12.750000\n",
      "50%       5.000000   33.000000       180.000000           16.500000\n",
      "75%       7.000000   40.000000       190.000000           18.000000\n",
      "max       8.000000  120.000000      5000.000000           20.000000\n",
      "\n",
      "Potential Outliers:\n",
      "   customer_id customer_name    age country  purchase_amount  \\\n",
      "4            5           Eve  120.0     USA           5000.0   \n",
      "\n",
      "   purchase_frequency  date  \n",
      "4                 NaN  None  \n"
     ]
    }
   ],
   "source": [
    "# Display first few rows\n",
    "print(\"\\nInitial Data:\")\n",
    "print(df.head())\n",
    "\n",
    "# Print data types of each column\n",
    "print(\"\\nData Types:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# Determine number of rows and columns\n",
    "print(\"\\nShape of Dataset:\")\n",
    "print(f\"Rows: {df.shape[0]}, Columns: {df.shape[1]}\")\n",
    "\n",
    "# Identify missing values\n",
    "print(\"\\nMissing Values:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Basic descriptive statistics for numerical columns\n",
    "print(\"\\nDescriptive Statistics:\")\n",
    "print(df.describe())\n",
    "\n",
    "# Identify potential outliers using IQR method for numerical columns\n",
    "Q1 = df[['age', 'purchase_amount']].quantile(0.25)\n",
    "Q3 = df[['age', 'purchase_amount']].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "outliers = df[((df[['age', 'purchase_amount']] < (Q1 - 1.5 * IQR)) | \n",
    "               (df[['age', 'purchase_amount']] > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "print(\"\\nPotential Outliers:\")\n",
    "print(outliers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fc3f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Phase 2: Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f526f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d36113a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After Handling Missing Values:\n",
      "   customer_id customer_name   age         country  purchase_amount  \\\n",
      "0            1         Alice  25.0             USA            100.5   \n",
      "2            3       Charlie  35.0              UK            200.0   \n",
      "3            4         David  45.0  United Kingdom            150.0   \n",
      "5            6         Frank  29.0              UK            120.0   \n",
      "7            8        Hannah  33.0             USA            180.0   \n",
      "8            8        hannah  33.0             usa            180.0   \n",
      "\n",
      "   purchase_frequency             date  \n",
      "0                10.0       2025-03-01  \n",
      "2                20.0       2025-01-01  \n",
      "3                15.0  March 3rd, 2025  \n",
      "5                12.0       03-04-2025  \n",
      "7                18.0       2025-01-01  \n",
      "8                18.0       2025-01-01  \n"
     ]
    }
   ],
   "source": [
    "# Impute missing age with the mean age (excluding the outlier)\n",
    "mean_age = df['age'][df['age'] < 100].mean()\n",
    "df['age'].fillna(mean_age, inplace=True)\n",
    "\n",
    "# Impute missing purchase_amount with the median value\n",
    "median_purchase_amount = df['purchase_amount'].median()\n",
    "df['purchase_amount'].fillna(median_purchase_amount, inplace=True)\n",
    "\n",
    "# Drop rows with missing purchase_frequency since it's critical for analysis\n",
    "df.dropna(subset=['purchase_frequency'], inplace=True)\n",
    "\n",
    "# Fill missing dates with a placeholder value for consistency\n",
    "df['date'].fillna('2025-01-01', inplace=True)\n",
    "\n",
    "print(\"\\nAfter Handling Missing Values:\")\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec5eff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Type Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19f890b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After Converting Date Column:\n",
      "customer_id                    int64\n",
      "customer_name                 object\n",
      "age                          float64\n",
      "country                       object\n",
      "purchase_amount              float64\n",
      "purchase_frequency           float64\n",
      "date                  datetime64[ns]\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Convert date column to datetime format\n",
    "df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "\n",
    "print(\"\\nAfter Converting Date Column:\")\n",
    "print(df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e84e8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Handling Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0bcddcc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Duplicate Records:\n",
      "Empty DataFrame\n",
      "Columns: [customer_id, customer_name, age, country, purchase_amount, purchase_frequency, date]\n",
      "Index: []\n",
      "\n",
      "After Removing Duplicates:\n",
      "   customer_id customer_name   age         country  purchase_amount  \\\n",
      "0            1         Alice  25.0             USA            100.5   \n",
      "2            3       Charlie  35.0              UK            200.0   \n",
      "3            4         David  45.0  United Kingdom            150.0   \n",
      "5            6         Frank  29.0              UK            120.0   \n",
      "7            8        Hannah  33.0             USA            180.0   \n",
      "\n",
      "   purchase_frequency       date  \n",
      "0                10.0 2025-03-01  \n",
      "2                20.0 2025-01-01  \n",
      "3                15.0        NaT  \n",
      "5                12.0        NaT  \n",
      "7                18.0 2025-01-01  \n"
     ]
    }
   ],
   "source": [
    "# Identify duplicates based on customer_id and customer_name combination\n",
    "duplicates = df[df.duplicated(subset=['customer_id', 'customer_name'])]\n",
    "print(\"\\nDuplicate Records:\")\n",
    "print(duplicates)\n",
    "\n",
    "# Remove duplicates from the dataset\n",
    "df.drop_duplicates(subset=['customer_id'], inplace=True)\n",
    "\n",
    "print(\"\\nAfter Removing Duplicates:\")\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f950749c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Addressing Inconsistencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2434841e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After Addressing Inconsistencies:\n",
      "   customer_id customer_name   age        country  purchase_amount  \\\n",
      "0            1         Alice  25.0  united states            100.5   \n",
      "2            3       Charlie  35.0             uk            200.0   \n",
      "3            4         David  45.0             uk            150.0   \n",
      "5            6         Frank  29.0             uk            120.0   \n",
      "7            8        Hannah  33.0  united states            180.0   \n",
      "\n",
      "   purchase_frequency       date  \n",
      "0                10.0 2025-03-01  \n",
      "2                20.0 2025-01-01  \n",
      "3                15.0        NaT  \n",
      "5                12.0        NaT  \n",
      "7                18.0 2025-01-01  \n"
     ]
    }
   ],
   "source": [
    "# Standardize text case for customer_name and country columns\n",
    "df['customer_name'] = df['customer_name'].str.title()\n",
    "df['country'] = df['country'].str.lower()\n",
    "\n",
    "# Correct inconsistent naming conventions in country column\n",
    "df['country'].replace({'usa': 'united states', \n",
    "                       'united kingdom': 'uk'}, inplace=True)\n",
    "\n",
    "print(\"\\nAfter Addressing Inconsistencies:\")\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf5bc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Outlier Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d775084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After Handling Outliers:\n",
      "   customer_id customer_name   age        country  purchase_amount  \\\n",
      "0            1         Alice  25.0  united states            100.5   \n",
      "2            3       Charlie  35.0             uk            196.0   \n",
      "3            4         David  43.0             uk            150.0   \n",
      "5            6         Frank  29.0             uk            120.0   \n",
      "7            8        Hannah  33.0  united states            180.0   \n",
      "\n",
      "   purchase_frequency       date  \n",
      "0                10.0 2025-03-01  \n",
      "2                20.0 2025-01-01  \n",
      "3                15.0        NaT  \n",
      "5                12.0        NaT  \n",
      "7                18.0 2025-01-01  \n"
     ]
    }
   ],
   "source": [
    "# Cap outliers in age and purchase_amount columns at the upper limit (95th percentile)\n",
    "age_upper_limit = df['age'].quantile(0.95)\n",
    "purchase_upper_limit = df['purchase_amount'].quantile(0.95)\n",
    "\n",
    "df.loc[df['age'] > age_upper_limit, 'age'] = age_upper_limit\n",
    "df.loc[df['purchase_amount'] > purchase_upper_limit, 'purchase_amount'] = purchase_upper_limit\n",
    "\n",
    "print(\"\\nAfter Handling Outliers:\")\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0787edfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Phase 3: Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79708e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19b2e0f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After Feature Engineering (Lifetime Value):\n",
      "   customer_id  lifetime_value\n",
      "0            1          1005.0\n",
      "2            3          3920.0\n",
      "3            4          2250.0\n",
      "5            6          1440.0\n",
      "7            8          3240.0\n"
     ]
    }
   ],
   "source": [
    "# Create a new feature: Customer Lifetime Value (CLV) based on purchase amount and frequency\n",
    "df['lifetime_value'] = df['purchase_amount'] * df['purchase_frequency']\n",
    "\n",
    "print(\"\\nAfter Feature Engineering (Lifetime Value):\")\n",
    "print(df[['customer_id', 'lifetime_value']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23052980",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Aggregation and Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ab3fac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Purchase Amount by Country:\n",
      "country\n",
      "uk               155.333333\n",
      "united states    140.250000\n",
      "Name: purchase_amount, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Group by country and calculate average purchase amount per country segment\n",
    "summary_stats = df.groupby('country')['purchase_amount'].mean()\n",
    "print(\"\\nAverage Purchase Amount by Country:\")\n",
    "print(summary_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fedcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2536e367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After Binning Age into Groups:\n",
      "   customer_id age_group\n",
      "0            1     18-35\n",
      "2            3     18-35\n",
      "3            4     36-50\n",
      "5            6     18-35\n",
      "7            8     18-35\n"
     ]
    }
   ],
   "source": [
    "# Bin age into categories (e.g., age groups)\n",
    "bins = [0, 18, 35, 50, np.inf]\n",
    "labels = ['Under-18', '18-35', '36-50', '50+']\n",
    "df['age_group'] = pd.cut(df['age'], bins=bins, labels=labels)\n",
    "\n",
    "print(\"\\nAfter Binning Age into Groups:\")\n",
    "print(df[['customer_id', 'age_group']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f534ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Phase 4: Reporting and Documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5fef2ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save Cleaned Dataset to File:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee6b452f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cleaned Dataset Saved to File.\n"
     ]
    }
   ],
   "source": [
    "# Save cleaned dataset to CSV file for further analysis or reporting.\n",
    "df.to_csv('cleaned_customer_data.csv', index=False)\n",
    "\n",
    "print(\"\\nCleaned Dataset Saved to File.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b047852b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Final Report Summary:\n",
    "\n",
    "    ##Initial Findings:\n",
    "\n",
    "       #1 Missing values were present in age, purchase_amount, purchase_frequency, and date.\n",
    "\n",
    "        #2 Outliers were identified in age (>100) and purchase_amount (>5000).\n",
    "\n",
    "        #3 Duplicate records were found based on customer_id.\n",
    "\n",
    "        #4 Inconsistent naming conventions existed in country.\n",
    "\n",
    "    ##Data Cleaning Decisions:\n",
    "\n",
    "        #1 Imputation was used for missing values.\n",
    "\n",
    "        #2 Outliers were capped at the upper limit using the IQR method.\n",
    "\n",
    "        #3 Text standardization was applied to categorical variables.\n",
    "\n",
    "    ##Data Transformation:\n",
    "\n",
    "        #1 New feature (lifetime_value) was created.\n",
    "\n",
    "        #2 Age was binned into categories for segmentation.\n",
    "\n",
    "    ##Limitations:\n",
    "\n",
    "        #1 Assumptions were made regarding missing values imputation.\n",
    "\n",
    "        #2 Placeholder dates may not reflect actual customer activity.\n",
    "        \n",
    "        ##### This approach ensures a clean dataset ready for analysis ####\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccc90cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
